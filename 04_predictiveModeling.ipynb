{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "96738ad8",
      "metadata": {
        "id": "96738ad8"
      },
      "source": [
        "# Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3275cd06",
      "metadata": {
        "id": "3275cd06"
      },
      "source": [
        "## Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab66999",
      "metadata": {
        "id": "7ab66999"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fVYnN9h4D24c",
      "metadata": {
        "id": "fVYnN9h4D24c"
      },
      "source": [
        "## SUPERVISED - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7cdec31",
      "metadata": {
        "id": "f7cdec31"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e14007",
      "metadata": {
        "id": "62e14007",
        "outputId": "7b9d380e-2f17-4ec3-e8e2-71883efebbb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC de Regresión Logística:  0.61\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(solver='newton-cg')\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc78400",
      "metadata": {
        "id": "0fc78400"
      },
      "source": [
        "### kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15491615",
      "metadata": {
        "id": "15491615",
        "outputId": "888de793-1ce5-4448-98f3-0fb9c3cfd0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC de KNN:  0.56\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3605f9a",
      "metadata": {
        "id": "b3605f9a"
      },
      "source": [
        "### NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b8d8e0",
      "metadata": {
        "id": "08b8d8e0",
        "outputId": "a064d472-66c6-4e3c-b529-36aaa40b3400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC de Naive Bayes:  0.57\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "naive_bayes = BernoulliNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "y_pred = naive_bayes.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97c3129",
      "metadata": {},
      "source": [
        "### DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a5f713",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = tree.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70acd7c9",
      "metadata": {},
      "source": [
        "### RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a61f82",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_forest.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ab969e",
      "metadata": {},
      "source": [
        "### XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6055e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "n_estimators = np.linspace(1,5,5)\n",
        "max_depths = [2,3,4]\n",
        "learning_rates = [1,2,3]\n",
        "for . in ... :\n",
        "  xgb_classifier = XGBClassifier(n_estimators=n, max_depth=md, learning_rate=lr, objective='binary:logistic')\n",
        "  score = xgb_classifier.fit(X_train, y_train).score(X_test, y_test)\n",
        "  #y_pred = xgb_classifier.predict_proba(X_test)[:,1]\n",
        "  scores.append(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293bc5a4",
      "metadata": {},
      "source": [
        "### LIGHTGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ef4c43",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "scores = []\n",
        "learning_rates =  np.linspace(0.1,1,9)\n",
        "warm_starts = [True, False]\n",
        "\n",
        "for . in ... :\n",
        "  hist_gradient_boosting = HistGradientBoostingClassifier(learning_rate=lr, warm_start=ws)\n",
        "  score = hist_gradient_boosting.fit(X_train, y_train).score(X_test, y_test)\n",
        "  #y_pred = hist_gradient_boosting.predict_proba(X_test)[:,1]\n",
        "  scores.append(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02122c26",
      "metadata": {},
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af7734b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "scores = []\n",
        "kernels =  ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "Cs = np.linspace(0.1,0.9,9*10)\n",
        "gammas = ['scale', 'auto']\n",
        "\n",
        "for . in ... :\n",
        "     score = svm.SVC(C=c, kernel=k, gamma=g).fit(X_train, y_train).score(X_test, y_test)\n",
        "    scores.append(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d69267",
      "metadata": {},
      "source": [
        "## UNSUPERVISED - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80139a74",
      "metadata": {
        "id": "80139a74"
      },
      "source": [
        "### k-MEANS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a196a215",
      "metadata": {},
      "source": [
        "Clusters data by trying to separate samples in _N_ groups of equal variance, minimizing the inertia (within-cluster sum-of-squares)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a63ab3e",
      "metadata": {
        "id": "0a63ab3e",
        "outputId": "a5e8185d-87d1-46a0-e258-3d2ca0682710"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\isaac\\miniconda3\\envs\\top_algos\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "C:\\Users\\isaac\\miniconda3\\envs\\top_algos\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([4, 0, 3, 2, 2, 1, 2, 1, 2, 0])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "kmeans.labels_[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5124b62e",
      "metadata": {},
      "source": [
        "### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5f9bf3a",
      "metadata": {},
      "source": [
        "Views clusters as areas of high density separated by areas of low density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "170b68e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=3, min_samples=2)\n",
        "dbscan.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b9a9e5",
      "metadata": {},
      "source": [
        "## SUPERVISED - Temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05aedc9",
      "metadata": {},
      "source": [
        "### ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03726c96",
      "metadata": {
        "id": "03726c96"
      },
      "outputs": [],
      "source": [
        "from pmdarima import auto_arima\n",
        "\n",
        "\n",
        "model = auto_arima(train_data, seasonal=False, suppress_warnings=True)\n",
        "model_fit = model.fit(train_data)\n",
        "predictions = model_fit.predict(n_periods=len(test_data))\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(df_st[-12:].index.strftime('%YQ%q'), df_st[-12:].infl, label='Realidad')\n",
        "# plt.plot(df_st[-4:].index.strftime('%YQ%q'), predictions, label='Predicción')\n",
        "# plt.xticks(rotation=45, fontsize=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470f27cf",
      "metadata": {
        "id": "470f27cf"
      },
      "source": [
        "### EXPONENTIAL SMOOTHING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecbe7cd",
      "metadata": {
        "id": "0ecbe7cd"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "model = ExponentialSmoothing(train_data, seasonal=None, trend='add')\n",
        "model_fit = model.fit()\n",
        "predictions = model_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_st[-12:].index.strftime('%YQ%q'), df_st[-12:].infl, label='Realidad')\n",
        "plt.plot(df_st[-4:].index.strftime('%YQ%q'), predictions, label='Predicción')\n",
        "plt.xticks(rotation=45, fontsize=8);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xKUnarYZELg7",
      "metadata": {
        "id": "xKUnarYZELg7"
      },
      "source": [
        "## PERFORMANCE METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WPJFIt4FIsYH",
      "metadata": {
        "id": "WPJFIt4FIsYH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y, clf.predict_proba(X)[:, 1]) #binary\n",
        "roc_auc_score(y, clf.predict_proba(X), multi_class='ovr') #regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tq-Zzb3EEwM3",
      "metadata": {
        "id": "Tq-Zzb3EEwM3"
      },
      "source": [
        "### CROSS VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pHmJqeJIEag8",
      "metadata": {
        "id": "pHmJqeJIEag8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv=10)\n",
        "print(round(scores.mean(),3), '+-', round(scores.std(),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FFCYJ5AsFFD6",
      "metadata": {
        "id": "FFCYJ5AsFFD6"
      },
      "source": [
        "### K-FOLD CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cObR0072Hg7r",
      "metadata": {
        "id": "cObR0072Hg7r"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "accuracy = []\n",
        "m = ['precision', 'recall', 'f1-score']\n",
        "metrics = {str(output_values[0]): {'precision': [], 'recall': [], 'f1-score': []},\n",
        "            str(output_values[1]): {'precision': [], 'recall': [], 'f1-score': []}}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clf = svm.SVC(C=0.75, kernel='rbf', gamma='scale')\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    for me in m:\n",
        "        metrics[str(output_values[0])][me].append(report['0'][me])\n",
        "        metrics[str(output_values[1])][me].append(report['1'][me])\n",
        "    accuracy.append(report['accuracy'])\n",
        "\n",
        "print()\n",
        "for me in m:\n",
        "    print(f'{me.upper()} {str(output_values[0])} - {round(np.mean(metrics[str(output_values[0])][me]),3)} +- {round(np.std(metrics[str(output_values[0])][me]),3)}')\n",
        "    print(f'{me.upper()} {str(output_values[1])} - {round(np.mean(metrics[str(output_values[1])][me]),3)} +- {round(np.std(metrics[str(output_values[1])][me]),3)}')\n",
        "    print()\n",
        "print(f\"Accuracy: {round(np.mean(accuracy),3)} +- {round(np.std(accuracy),3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YgC6KtreFODU",
      "metadata": {
        "id": "YgC6KtreFODU"
      },
      "source": [
        "### REPEATED K-FOLD CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EWh00Ea2FQOs",
      "metadata": {
        "id": "EWh00Ea2FQOs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=23)\n",
        "\n",
        "accuracy = []\n",
        "m = ['precision', 'recall', 'f1-score']\n",
        "metrics = {str(output_values[0]): {'precision': [], 'recall': [], 'f1-score': []},\n",
        "            str(output_values[1]): {'precision': [], 'recall': [], 'f1-score': []}}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rkf.split(X)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clf = svm.SVC(C=0.75, kernel='rbf', gamma='scale')\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    for me in m:\n",
        "        metrics[str(output_values[0])][me].append(report['0'][me])\n",
        "        metrics[str(output_values[1])][me].append(report['1'][me])\n",
        "    accuracy.append(report['accuracy'])\n",
        "\n",
        "print()\n",
        "for me in m:\n",
        "    print(f'{me.upper()} {str(output_values[0])} - {round(np.mean(metrics[str(output_values[0])][me]),3)} +- {round(np.std(metrics[str(output_values[0])][me]),3)}')\n",
        "    print(f'{me.upper()} {str(output_values[1])} - {round(np.mean(metrics[str(output_values[1])][me]),3)} +- {round(np.std(metrics[str(output_values[1])][me]),3)}')\n",
        "    print()\n",
        "print(f\"Accuracy: {round(np.mean(accuracy),3)} +- {round(np.std(accuracy),3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l46G0SLUExza",
      "metadata": {
        "id": "l46G0SLUExza"
      },
      "source": [
        "### K-FOLD CV STRATIFIED"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wIp_I__LFDM6",
      "metadata": {
        "id": "wIp_I__LFDM6"
      },
      "source": [
        "A variation of k-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4QGKAcZlEN2T",
      "metadata": {
        "id": "4QGKAcZlEN2T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "kf = StratifiedKFold(n_splits=4)\n",
        "\n",
        "accuracy = []\n",
        "m = ['precision', 'recall', 'f1-score']\n",
        "metrics = {str(output_values[0]): {'precision': [], 'recall': [], 'f1-score': []},\n",
        "            str(output_values[1]): {'precision': [], 'recall': [], 'f1-score': []}}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clf = svm.SVC(C=0.75, kernel='rbf', gamma='scale')\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    for me in m:\n",
        "        metrics[str(output_values[0])][me].append(report['0'][me])\n",
        "        metrics[str(output_values[1])][me].append(report['1'][me])\n",
        "    accuracy.append(report['accuracy'])\n",
        "\n",
        "print()\n",
        "for me in m:\n",
        "    print(f'{me.upper()} {str(output_values[0])} - {round(np.mean(metrics[str(output_values[0])][me]),3)} +- {round(np.std(metrics[str(output_values[0])][me]),3)}')\n",
        "    print(f'{me.upper()} {str(output_values[1])} - {round(np.mean(metrics[str(output_values[1])][me]),3)} +- {round(np.std(metrics[str(output_values[1])][me]),3)}')\n",
        "    print()\n",
        "print(f\"Accuracy: {round(np.mean(accuracy),3)} +- {round(np.std(accuracy),3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e1db20",
      "metadata": {},
      "source": [
        "### STRATIFIED SHUFFLE SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DFbVusoaEY9b",
      "metadata": {
        "id": "DFbVusoaEY9b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "sh = StratifiedShuffleSplit(n_splits=4, test_size=0.2)\n",
        "\n",
        "accuracy = []\n",
        "m = ['precision', 'recall', 'f1-score']\n",
        "metrics = {'noKC': {'precision': [], 'recall': [], 'f1-score': []},\n",
        "            'KC': {'precision': [], 'recall': [], 'f1-score': []}}\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(sh.split(X, y)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clf = svm.SVC(C=0.75, kernel='rbf', gamma='scale')\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    for me in m:\n",
        "        metrics[str(output_values[0])][me].append(report['0'][me])\n",
        "        metrics[str(output_values[1])][me].append(report['1'][me])\n",
        "    accuracy.append(report['accuracy'])\n",
        "\n",
        "print()\n",
        "for me in m:\n",
        "    print(f'{me.upper()} {str(output_values[0])} - {round(np.mean(metrics[str(output_values[0])][me]),3)} +- {round(np.std(metrics[str(output_values[0])][me]),3)}')\n",
        "    print(f'{me.upper()} {str(output_values[1])} - {round(np.mean(metrics[str(output_values[1])][me]),3)} +- {round(np.std(metrics[str(output_values[1])][me]),3)}')\n",
        "    print()\n",
        "print(f\"Accuracy: {round(np.mean(accuracy),3)} +- {round(np.std(accuracy),3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1020ade6",
      "metadata": {},
      "source": [
        "### Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f14bd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.model_selection import ValidationCurveDisplay\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_scores, valid_scores = validation_curve(\n",
        "    SVC(kernel=\"linear\"), X, y, param_name=\"C\", param_range=np.logspace(-7, 3, 3),\n",
        ")\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y, random_state=0)\n",
        "\n",
        "ValidationCurveDisplay.from_estimator(SVC(kernel=\"linear\"), X, y, param_name=\"C\", param_range=np.logspace(-7, 3, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8848d20d",
      "metadata": {},
      "source": [
        "### Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5158846e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import LearningCurveDisplay\n",
        "\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    SVC(kernel='linear'), X, y, train_sizes=[50, 80, 110], cv=5)\n",
        "\n",
        "print(train_sizes)\n",
        "print(train_scores)\n",
        "print(valid_scores)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y, random_state=0)\n",
        "\n",
        "LearningCurveDisplay.from_estimator(\n",
        "   SVC(kernel=\"linear\"), X, y, train_sizes=[50, 80, 110], cv=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "b0def974"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "376px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
